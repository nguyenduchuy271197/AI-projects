{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMlLJDx1V4L6typHkLZdN97"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"sa7dw0Fy1lU-","executionInfo":{"status":"ok","timestamp":1603982391783,"user_tz":-420,"elapsed":1125,"user":{"displayName":"HUY Nguyễn Đức","photoUrl":"","userId":"13128002747883215974"}},"outputId":"3605d7db-109e-43aa-ad06-698533ee5ee3","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"acjzlWZN1uSK","executionInfo":{"status":"ok","timestamp":1603982395256,"user_tz":-420,"elapsed":3294,"user":{"displayName":"HUY Nguyễn Đức","photoUrl":"","userId":"13128002747883215974"}},"outputId":"236588d2-8ba6-4c86-f656-fc80c46d5f85","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd 'drive/My Drive/AI projects/DogsvsCats'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/AI projects/DogsvsCats\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DhdkGb3O1vpE","executionInfo":{"status":"ok","timestamp":1603982395260,"user_tz":-420,"elapsed":1560,"user":{"displayName":"HUY Nguyễn Đức","photoUrl":"","userId":"13128002747883215974"}},"outputId":"670ae688-edd2-4931-c22d-93755573a42c","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["import pandas as pd\n","data = pd.read_csv('data.csv')\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cat.9089.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cat.9110.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cat.9079.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cat.9096.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cat.909.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       filename label\n","0  cat.9089.jpg   cat\n","1  cat.9110.jpg   cat\n","2  cat.9079.jpg   cat\n","3  cat.9096.jpg   cat\n","4   cat.909.jpg   cat"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"rV634FqyzFqU"},"source":["import os\n","def check_exist(filename):\n","  if filename not in os.listdir('train'):\n","    return filename\n","data['filename'].apply(lambda x: check_exist(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VSZUzgjUy9HU"},"source":["image_files = os.listdir('train')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgyWZeEn2CEH"},"source":["cat_data = data[data['label'] == 'cat'][:8000]\n","dog_data = data[data['label'] == 'dog'][:8000]\n","data = pd.concat([cat_data,dog_data])\n","data.reset_index(drop= True, inplace= True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aB1GJSX2bKQ","executionInfo":{"status":"ok","timestamp":1603982115492,"user_tz":-420,"elapsed":32575,"user":{"displayName":"HUY Nguyễn Đức","photoUrl":"","userId":"13128002747883215974"}},"outputId":"479d2a99-dd81-4a28-c64c-357261461bd0","colab":{"base_uri":"https://localhost:8080/"}},"source":["from sklearn.model_selection import train_test_split\n","train_data, val_data = train_test_split(data, test_size= 0.2, random_state= 2020)\n","train_data.reset_index(drop= True, inplace= True)\n","val_data.reset_index(drop= True, inplace= True)\n","len(train_data), len(val_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12800, 3200)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"abq7-L472xdZ"},"source":["# Custom dataset\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","from PIL import Image\n","\n","class DogCatDataset(nn.Module):\n","  def __init__(self, dataframe, directory, transforms= None):\n","    self.df = dataframe\n","    self.dir = directory\n","    self.transforms= transforms\n","    self.class_dict = {'cat': 0 , 'dog': 1}\n","    self.df['class'] = self.df['label'].apply(lambda x: self.class_dict[x])\n","    self.IMAGE_SIZE = 128\n","\n","  def __len__(self):\n","    return len(self.df)\n","\n","  def __getitem__(self, index):\n","    image_file = self.df.loc[index, 'filename']\n","    image_path = os.path.join(self.dir, image_file)\n","    image = Image.open(image_path).convert('RGB').resize((self.IMAGE_SIZE, self.IMAGE_SIZE))\n","\n","    label = torch.tensor(float(self.df.loc[index, 'class']))\n","    \n","    if self.transforms:\n","      image = self.transforms(image)\n","\n","    return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDZBfjJE6r2V"},"source":["# Transforms\n","from torchvision import transforms\n","IMAGE_MEAN = [0.5, 0.5, 0.5]\n","IMAGE_STD = [0.5, 0.5, 0.5]\n","\n","train_transforms = transforms.Compose([\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize(IMAGE_MEAN, IMAGE_STD)\n","])\n","\n","val_transforms = transforms.Compose([\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize(IMAGE_MEAN, IMAGE_STD)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ykx2Z6zC26_s","executionInfo":{"status":"ok","timestamp":1603982119085,"user_tz":-420,"elapsed":36149,"user":{"displayName":"HUY Nguyễn Đức","photoUrl":"","userId":"13128002747883215974"}},"outputId":"27c31a7b-50dc-4fec-c76c-75dd65e9f0f2","colab":{"base_uri":"https://localhost:8080/"}},"source":["from torch.utils.data import DataLoader\n","\n","TRAIN_DIR = 'train'\n","BATCH_SIZE = 32\n","\n","train_ds = DogCatDataset(train_data, TRAIN_DIR, transforms= train_transforms)\n","val_ds = DogCatDataset(val_data, TRAIN_DIR, transforms= val_transforms)\n","\n","train_dl = DataLoader(train_ds, batch_size= BATCH_SIZE, shuffle= True)\n","val_dl = DataLoader(val_ds, batch_size= BATCH_SIZE, shuffle= False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"pyVu5z-y7gHT"},"source":["class CNN(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(3, 32, 3)\n","    # self.bn1 = nn.BatchNorm2d(126*126*32)\n","    self.conv2 = nn.Conv2d(32, 64, 3)\n","    # self.bn2 = nn.BatchNorm2d(61*61*64)\n","    self.conv3 = nn.Conv2d(64, 128, 3)\n","    # self.bn3 = nn.BatchNorm2d(28*28*128)\n","    self.flatten = nn.Flatten()\n","    self.linear1 = nn.Linear(14*14*128, 512)\n","    # self.bn4 = nn.BatchNorm1d(512)\n","    self.linear2 = nn.Linear(512, 1)\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = F.relu(x)\n","    # x = self.bn1(x)\n","    x = F.max_pool2d(x, (2,2))\n","    x = F.dropout(x, 0.25)\n","\n","    x = self.conv2(x)\n","    x = F.relu(x)\n","    # x = self.bn2(x)\n","    x = F.max_pool2d(x, (2,2))\n","    x = F.dropout(x, 0.25)\n","\n","    x = self.conv3(x)\n","    x = F.relu(x)\n","    # x = self.bn3(x)\n","    x = F.max_pool2d(x, (2,2))\n","    x = F.dropout(x, 0.25)\n","\n","    x = self.flatten(x)\n","    x = self.linear1(x)\n","    x = F.relu(x)\n","    # x = self.bn4(x)\n","    x = F.dropout(x, 0.5)\n","    x = self.linear2(x)\n","    x = F.sigmoid(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFZY-EeuILWr","executionInfo":{"status":"error","timestamp":1603982179470,"user_tz":-420,"elapsed":96520,"user":{"displayName":"HUY Nguyễn Đức","photoUrl":"","userId":"13128002747883215974"}},"outputId":"2a4c3b0b-ba01-465c-9282-4addc16a59ab","colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["# Show a batch\n","for image_batch, label_batch in train_dl:\n","  print(image_batch.shape)\n","  print(label_batch)\n","  break"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-8d42cf32776f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Show a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-a5637469ad59>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: 'train/dog.4913.jpg'"]}]},{"cell_type":"code","metadata":{"id":"AgJXZhdPI5kI"},"source":["# Show image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torchvision.utils import make_grid\n","\n","images, labels = next(iter(train_dl))\n","def show_image_batch(images):\n","  plt.figure(figsize = (16,24))\n","  grid_imgs = make_grid(images)\n","  np_grid_imgs = grid_imgs.numpy().transpose(1, 2, 0)\n","  np_grid_imgs = np_grid_imgs*np.array(IMAGE_STD) + np.array(IMAGE_MEAN)\n","  np_grid_imgs = np.clip(np_grid_imgs, 0, 1)\n","  plt.imshow(np_grid_imgs)\n","\n","show_image_batch(images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DSwCeRTTMsuU"},"source":["device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPp02OGritFn"},"source":["IMAGE_SIZE = 128\n","model = CNN()\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dMUQP8C5jpaP"},"source":["LR = 1e-3\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr= LR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-oUiQX2Omdy5"},"source":["train_losses = []\n","val_losses = []\n","val_accuracy_list = []\n","total_steps = []\n","step = 0\n","running_loss = 0\n","print_every = 5\n","num_epochs = 2\n","\n","for epoch in range(num_epochs):\n","  for inputs, labels in train_dl:\n","    inputs, labels = inputs.to(device), labels.to(device)\n","\n","    # Zero gradient\n","    optimizer.zero_grad()\n","\n","    # Forward\n","    outputs = model(inputs).long()\n","\n","    # Loss function\n","    loss = criterion(outputs, labels)\n","\n","    # Backward\n","    loss.backward()\n","\n","    # Update parameters\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","\n","    if step % print_every == 0:\n","      val_loss = 0\n","      val_accuracy = 0\n","      model.eval()\n","      with torch.no_grad():\n","        for inputs, labels in val_dl:\n","          inputs, labels = inputs.to(device), labels.to(device)\n","\n","          # Forward\n","          predictions = model(inputs)\n","\n","          # Val loss\n","          batch_loss = criterion(predictions, labels)\n","\n","          val_loss += batch_loss.item()\n","\n","          # Calculate accuracy\n","          class_pred = torch.where(predictions < 0.5, torch.tensor(0.), torch.tensor(1.))\n","          val_accuracy += torch.sum(class_pred == labels).item()/len(val_data)\n","\n","      train_losses.append(running_loss/print_every)\n","      val_losses.append(val_loss/len(val_dl))\n","      val_accuracy_list.append(val_accuracy)\n","      total_steps.append(step)\n","      print(f'Device {device}.. Epoch {epoch+1}/{num_epoch}.. Step {step}.. Train loss: {running_loss/print_every:.3f}.. val loss: {val_loss/len(val_dl):.3f}.. val acc: {val_accuracy:.3f}')\n","      running_loss = 0\n","      model.train()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xuvjxtIHP4KU"},"source":[""],"execution_count":null,"outputs":[]}]}